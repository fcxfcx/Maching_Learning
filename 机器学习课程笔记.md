# 机器学习课程笔记

课程链接：[ML 2022 Spring (ntu.edu.tw)](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php)

## 一、机器学习、深度学习的基本概念

什么是机器学习？用一句话来描述，就是让机器拥有去寻找函数的能力。（例如，寻找可以将声音信号识别成文字的函数）我们给出一个输入，通过机器学习来构造一个函数来获取我们需要的输出，下面是不同的函数类型：

**Regression**: The function outputs a scalar （输出一个数值的函数）

**Classification**: Given options (classes), the function outputs the correct one （分类、区分的函数，例如Alpha Go下围棋的过程其实也是Classification，给出棋盘上19*19的选项去选出最佳的一项）

### 1.1 关于预测频道观看人数的例子

能否使用机器学习的方法，根据历史的观看人数，去预测某频道接下来一天的观看人数？如果要做这样一件事，我们可以先去思考这样的一个函数会是什么样子的：

假设y是我们想知道的结果（预测的观看人数），x~1~ 是我们已知的信息（历史数据），可以推测可能的函数构造是$y=b+wx_1$ 其中b和$w$就是我们未知的参数。而如何去获取这些未知的参数就需要一些Domain knowledge，即对于具体问题的一些背景知识理解。

这个带有未知参数的Function，在机器学习中就被称为**Model**（模型），而$x_1$则被称为**Feature**，$w$被称为**Weight**，b则被称为**Bias**。另外一个重要的概念是**Loss**，它是一个函数，接收之前提到的未知参数为输入，并且评估输入的一组参数有多好，可以表示为$L=(b,w)$。这样描述还是略微抽象，可以结合本节的例子更好的理解Loss

### 1.2 如何理解Loss

假设我们知道了一组未知参数（作为Loss的输入），我们就可以构造出一个暂时的Function，而我们拥有历史的真实数据，对每一天的观看人数，我们可以使用构造出的Function去进行运算并得出后一天的预测人数，而对于历史数据来说后一天的真实人数是已知的，因此对于第n天的预测结果我们会得到一个差值$e_n$，当然这个差值不一定是简单的相减，只需要理解为真实值和预测值之间的误差程度，而对于很多天的历史数据而言，我们会计算出很多个差值，Loss也可以表示为$L=\frac{1}{N}\sum_{i=1}^{n}{e_i}$，很好理解的是当L越大说明函数的效果越差。

如果用差值的绝对值去计算误差，得出的Loss会被称为Mean Absolute Error（MAE），如果用差值的平方的方式去计算，则会被称为Mean Square Error（MSE）

MAE和MSE的区别：[机器学习常用损失函数小结 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/77686118)



### 1.3  关于Optimization

这一步是机器学习的第三步，但我们已知了如何去评判选出参数的表现的时候，我们的任务就变成了如何选取最佳的参数。这个过程就是Optimization。在这一步里面我们用到的方法是**Gradient Descent**（梯度下降法），它的步骤可以简述为（这里简化了，只考虑了$w$而忽略了b）：

- 随机选取一个初始值$w^0$
- 计算w对Loss的微分是多少：$\frac{\delta L}{\delta w}|_{w=w^0}$ 或者说就是计算在$w^0$处的切线斜率
- 很明显，当斜率为正的时候，减小$w$的值会降低Loss，当斜率为负的时候，增加$w$的值会降低Loss 
- 如何确定$w$的值要更改多少呢？它的表达是$\eta\frac{\delta L}{\delta w}|_{w=w^0}$，这里$\eta$是learning rate，该值需要自己去确定
- 根据$w^1 = w^0 -\eta\frac{\delta L}{\delta w}|_{w=w^0}$更新$w$的值
- 如果当斜率为零的时候，此时$w$的值也不能再改变，这个点称为**Local minima**，但是注意这个点可能并不是Loss最小的点，使得Loss最小的点被称为**Global minima**

这个过程也可以很容易的推广到考虑多个参数的情况，并且计算斜率的过程在大多数的深度学习框架里都包装成了简单的方法。

继续回到之前提到的例子，我们会发现整个训练过程完成后，得出的参数所构造的函数其实表现并不尽人意。这也很好理解，因为我们所假设的函数格式过于简单了，我们只是简单的认为后一天的观看人数和前一天的相关。如果我们考虑更多的数据，去将历史数据更充分的使用，例如使用前七天的观看人数去预测，将函数假设为如下结构：
$$
y= b + \sum_{j=1}^{7}{w_j}{i_j}
$$
我们会发现Loss的值会更小，也就是说训练出来模型的效果更好了。我们甚至可以再进一步，去用更多的历史数据，例如28天、56天甚至更多，也会有更好的模型效果（但是可能到某一个点再继续升高日子并不会提升了）。基于这个思路去假设的函数结构被称为**Linear Model**（线性模型），而这种结果也确实太过简单了。这种由于模型结构过于简单而产生的问题被称为Model Bias，即模型无法去模拟真实的状况。

### 1.4 进一步复杂的Function

前面提到我们使用线性的模型时，无论怎样调整参数，得出的图形也只会是一条直线。而很显然现实情况往往没有这么简单，关于观看人数的曲线呈现一个更复杂的形状（例如多个转折的曲线），我们可以尝试将预测模型更换为一个常数和一组折线的和，而这个折线往往表示为一条S形的曲线，称为Sigmoid Function，它的公式表达是：
$$
y= c \frac{1}{1+e^{-(b+wx_1)}}= c\ sigmoid(b+wx_1)
$$
这样的改变可以理解为，我们带入了更多的Feature，从而减小Model Bias，相应的模型可以表示为：
$$
y=b+\sum_{i}{c_i \ sigmoid(b_i+\sum_{j}{w_{ij}x_j})}
$$
这里的$i$是sigmoid函数的编号，而$j$则是feature的编号（这里的x就是日期），下面将这个模型表示为了图示和更简洁的公式表示，其中右侧的b，W和x是矩阵表示，因为括号内部的累加可以表示为矩阵乘法。而经过sigmoid方程后它们则表现为三条不同的曲线。

![](D:\研究生\西财学习项目\第一周\图片1.png)

这样的表示也带来了更多的参数，除了x为feature以外，其他都是需要确定的参数，注意这里的W等都是矩阵，因此将它们展开实际上是多个需要确定的参数，我们把这些参数全部列出来，归纳表达为$\theta$，同样我们需要去计算Loss来评价这些参数的表现。

同样的，在选取一个初始值之后，对于每个参数，都需要去与L进行微分计算，这样就得出了一个向量，内部是所有参数对L做微分计算的结果，表示为：$g=\nabla L(\theta^0)$，这里用的是初始点做例子。而在更新过程中，会根据learning rate同时更新所有的参数，即$\theta^0-\eta g \rightarrow \theta^1$。而在实际操作时，往往数据量会非常大，而常见的作法是将其分为多个**batch**，而每次计算Loss的时候使用不同的batch，当使用完一轮batch的时候就称为一个**epoch**。例如有一万条数据，而一个Batch的数量是10，则有1000个batch，那么每一个epoch内就更新了1000次参数。

除了Sigmoid函数，还有一个替代的方案是使用Rectified Linear Unit（ReLU）,ReLU的表达式是$c\ max(0,b+wx_1)$，从式子也很容易看出来它的形状，而这里如果我们把两个ReLU加起来，就可以得到一个Hard Sigmoid Function。这两种方式都是将模型复杂化以更贴近真实情况的方式，课程中使用的更多是ReLU的方式。

![](D:\研究生\西财学习项目\第一周\图片2.png)

实际上，我们可以更进一步，进行多次的ReLU嵌套（即将前一个ReLU函数的输出作为下一个函数的输入），这样可以认为是形成了多个layer，实验证明layer的增加同样会降低Loss的值，也就是说模型又进一步被优化了。这些一个个Sigmoid或者ReLU被称为Neuron（神经元），而一层层嵌套下去的这个网络，就被称为**Neural Network**，即神经网络。不过神经网络是很早就出现过的概念，而当时过于夸大导致名声并不好，后来又将每一层称为了hidden layer，而这一层一层的网络就更名为了**Deep Learning**。当然，并不是一味的增加层数就能产生更好的模型，当发现增加层数反而会增大Loss的时候，这个问题就被称为**Overfitting**（过拟合）。



思考：为什么MAE服从拉普拉斯分布而MSE服从正态分布（高斯分布）的